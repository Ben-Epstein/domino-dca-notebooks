{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "429fe8db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in ./.venv/lib/python3.9/site-packages (0.0.post5)\n",
      "Requirement already satisfied: flaml in ./.venv/lib/python3.9/site-packages (1.2.3)\n",
      "Collecting mlflow\n",
      "  Downloading mlflow-2.3.1-py3-none-any.whl (17.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.7/17.7 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: NumPy>=1.17.0rc1 in ./.venv/lib/python3.9/site-packages (from flaml) (1.24.2)\n",
      "Requirement already satisfied: lightgbm>=2.3.1 in ./.venv/lib/python3.9/site-packages (from flaml) (3.3.5)\n",
      "Requirement already satisfied: xgboost>=0.90 in ./.venv/lib/python3.9/site-packages (from flaml) (1.7.5)\n",
      "Requirement already satisfied: scipy>=1.4.1 in ./.venv/lib/python3.9/site-packages (from flaml) (1.10.1)\n",
      "Requirement already satisfied: pandas>=1.1.4 in ./.venv/lib/python3.9/site-packages (from flaml) (2.0.0)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in ./.venv/lib/python3.9/site-packages (from flaml) (1.2.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in ./.venv/lib/python3.9/site-packages (from mlflow) (8.1.3)\n",
      "Collecting cloudpickle<3 (from mlflow)\n",
      "  Using cached cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Collecting databricks-cli<1,>=0.8.7 (from mlflow)\n",
      "  Downloading databricks-cli-0.17.7.tar.gz (83 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting entrypoints<1 (from mlflow)\n",
      "  Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "Collecting gitpython<4,>=2.1.0 (from mlflow)\n",
      "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml<7,>=5.1 in ./.venv/lib/python3.9/site-packages (from mlflow) (6.0)\n",
      "Collecting protobuf<5,>=3.12.0 (from mlflow)\n",
      "  Downloading protobuf-4.23.0-cp37-abi3-macosx_10_9_universal2.whl (400 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.3/400.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytz<2024 in ./.venv/lib/python3.9/site-packages (from mlflow) (2023.3)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in ./.venv/lib/python3.9/site-packages (from mlflow) (2.28.2)\n",
      "Requirement already satisfied: packaging<24 in ./.venv/lib/python3.9/site-packages (from mlflow) (23.1)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<7,>=3.7.0 in ./.venv/lib/python3.9/site-packages (from mlflow) (6.4.1)\n",
      "Collecting sqlparse<1,>=0.4.0 (from mlflow)\n",
      "  Downloading sqlparse-0.4.4-py3-none-any.whl (41 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting alembic!=1.10.0,<2 (from mlflow)\n",
      "  Downloading alembic-1.10.4-py3-none-any.whl (212 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.9/212.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting docker<7,>=4.0.0 (from mlflow)\n",
      "  Downloading docker-6.1.1-py3-none-any.whl (147 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.9/147.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting Flask<3 (from mlflow)\n",
      "  Downloading Flask-2.3.2-py3-none-any.whl (96 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.9/96.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting querystring-parser<2 (from mlflow)\n",
      "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
      "Collecting sqlalchemy<3,>=1.4.0 (from mlflow)\n",
      "  Downloading SQLAlchemy-2.0.12-cp39-cp39-macosx_10_9_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyarrow<12,>=4.0.0 in ./.venv/lib/python3.9/site-packages (from mlflow) (11.0.0)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in ./.venv/lib/python3.9/site-packages (from mlflow) (3.4.3)\n",
      "Collecting matplotlib<4 (from mlflow)\n",
      "  Downloading matplotlib-3.7.1-cp39-cp39-macosx_10_12_x86_64.whl (7.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting gunicorn<21 (from mlflow)\n",
      "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Jinja2<4,>=2.11 in ./.venv/lib/python3.9/site-packages (from mlflow) (3.1.2)\n",
      "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
      "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in ./.venv/lib/python3.9/site-packages (from alembic!=1.10.0,<2->mlflow) (4.5.0)\n",
      "Collecting pyjwt>=1.7.0 (from databricks-cli<1,>=0.8.7->mlflow)\n",
      "  Downloading PyJWT-2.7.0-py3-none-any.whl (22 kB)\n",
      "Collecting oauthlib>=3.1.0 (from databricks-cli<1,>=0.8.7->mlflow)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tabulate>=0.7.7 (from databricks-cli<1,>=0.8.7->mlflow)\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: six>=1.10.0 in ./.venv/lib/python3.9/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.16.0)\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.26.7 in ./.venv/lib/python3.9/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.26.15)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in ./.venv/lib/python3.9/site-packages (from docker<7,>=4.0.0->mlflow) (1.5.1)\n",
      "Collecting Werkzeug>=2.3.3 (from Flask<3->mlflow)\n",
      "  Downloading Werkzeug-2.3.4-py3-none-any.whl (242 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting itsdangerous>=2.1.2 (from Flask<3->mlflow)\n",
      "  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Collecting blinker>=1.6.2 (from Flask<3->mlflow)\n",
      "  Downloading blinker-1.6.2-py3-none-any.whl (13 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=2.1.0->mlflow)\n",
      "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=3.0 in ./.venv/lib/python3.9/site-packages (from gunicorn<21->mlflow) (58.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in ./.venv/lib/python3.9/site-packages (from importlib-metadata!=4.7.0,<7,>=3.7.0->mlflow) (3.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.9/site-packages (from Jinja2<4,>=2.11->mlflow) (2.0.1)\n",
      "Requirement already satisfied: wheel in ./.venv/lib/python3.9/site-packages (from lightgbm>=2.3.1->flaml) (0.40.0)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib<4->mlflow)\n",
      "  Downloading contourpy-1.0.7-cp39-cp39-macosx_10_9_x86_64.whl (244 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cycler>=0.10 (from matplotlib<4->mlflow)\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib<4->mlflow)\n",
      "  Downloading fonttools-4.39.4-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1 (from matplotlib<4->mlflow)\n",
      "  Downloading kiwisolver-1.4.4-cp39-cp39-macosx_10_9_x86_64.whl (65 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow>=6.2.0 in ./.venv/lib/python3.9/site-packages (from matplotlib<4->mlflow) (9.5.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib<4->mlflow)\n",
      "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.9/site-packages (from matplotlib<4->mlflow) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./.venv/lib/python3.9/site-packages (from matplotlib<4->mlflow) (5.12.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./.venv/lib/python3.9/site-packages (from pandas>=1.1.4->flaml) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2.17.3->mlflow) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2.17.3->mlflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2.17.3->mlflow) (2022.12.7)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./.venv/lib/python3.9/site-packages (from scikit-learn>=0.24->flaml) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.venv/lib/python3.9/site-packages (from scikit-learn>=0.24->flaml) (3.1.0)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy<3,>=1.4.0->mlflow)\n",
      "  Downloading greenlet-2.0.2-cp39-cp39-macosx_11_0_x86_64.whl (241 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.4/241.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow)\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Collecting MarkupSafe>=2.0 (from Jinja2<4,>=2.11->mlflow)\n",
      "  Downloading MarkupSafe-2.1.2-cp39-cp39-macosx_10_9_x86_64.whl (13 kB)\n",
      "Building wheels for collected packages: databricks-cli\n",
      "  Building wheel for databricks-cli (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for databricks-cli: filename=databricks_cli-0.17.7-py3-none-any.whl size=143882 sha256=03bb3484a8c5f47a99f643af789e7158bf527c6100a5d31bf1c9ea83a3b6e773\n",
      "  Stored in directory: /Users/benepstein/Library/Caches/pip/wheels/b6/90/68/94d223a35a3910c1512a8d42d9f8333ce567ef26e250a56227\n",
      "Successfully built databricks-cli\n",
      "Installing collected packages: tabulate, sqlparse, smmap, querystring-parser, pyparsing, pyjwt, protobuf, oauthlib, MarkupSafe, kiwisolver, itsdangerous, gunicorn, greenlet, fonttools, entrypoints, cycler, contourpy, cloudpickle, blinker, Werkzeug, sqlalchemy, matplotlib, Mako, gitdb, docker, databricks-cli, gitpython, Flask, alembic, mlflow\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 2.0.1\n",
      "    Uninstalling MarkupSafe-2.0.1:\n",
      "      Successfully uninstalled MarkupSafe-2.0.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "solara 1.12.0 requires MarkupSafe<2.1, but you have markupsafe 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Flask-2.3.2 Mako-1.2.4 MarkupSafe-2.1.2 Werkzeug-2.3.4 alembic-1.10.4 blinker-1.6.2 cloudpickle-2.2.1 contourpy-1.0.7 cycler-0.11.0 databricks-cli-0.17.7 docker-6.1.1 entrypoints-0.4 fonttools-4.39.4 gitdb-4.0.10 gitpython-3.1.31 greenlet-2.0.2 gunicorn-20.1.0 itsdangerous-2.1.2 kiwisolver-1.4.4 matplotlib-3.7.1 mlflow-2.3.1 oauthlib-3.2.2 protobuf-4.23.0 pyjwt-2.7.0 pyparsing-3.0.9 querystring-parser-1.2.4 smmap-5.0.0 sqlalchemy-2.0.12 sqlparse-0.4.4 tabulate-0.9.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn flaml mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d31cb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For compilers to find libomp you may need to set:\n",
    "# import os\n",
    "# os.environ['LDFLAGS']=\"-L/usr/local/opt/libomp/lib\"\n",
    "# os.environ['CPPFLAGS']=\"-I/usr/local/opt/libomp/include\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15ba349b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.datasets\n",
    "\n",
    "# df = pd.read_csv(\"/Users/benepstein/Downloads/diabetes.csv\")\n",
    "data = sklearn.datasets.load_breast_cancer(as_frame=True)\n",
    "# df[\"target\"]\n",
    "df = data[\"data\"]\n",
    "df[\"outcome\"] = data[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "614a7723",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness   \n",
       "0          17.99         10.38          122.80     1001.0          0.11840  \\\n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry   \n",
       "0             0.27760         0.30010              0.14710         0.2419  \\\n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area   \n",
       "0                   0.07871  ...          17.33           184.60      2019.0  \\\n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity   \n",
       "0             0.16220            0.66560           0.7119  \\\n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  outcome  \n",
       "0                  0.2654          0.4601                  0.11890        0  \n",
       "1                  0.1860          0.2750                  0.08902        0  \n",
       "2                  0.2430          0.3613                  0.08758        0  \n",
       "3                  0.2575          0.6638                  0.17300        0  \n",
       "4                  0.1625          0.2364                  0.07678        0  \n",
       "..                    ...             ...                      ...      ...  \n",
       "564                0.2216          0.2060                  0.07115        0  \n",
       "565                0.1628          0.2572                  0.06637        0  \n",
       "566                0.1418          0.2218                  0.07820        0  \n",
       "567                0.2650          0.4087                  0.12400        0  \n",
       "568                0.0000          0.2871                  0.07039        1  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4131bf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness   \n",
       "0          17.99         10.38          122.80     1001.0          0.11840  \\\n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry   \n",
       "0             0.27760         0.30010              0.14710         0.2419  \\\n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area   \n",
       "0                   0.07871  ...          17.33           184.60      2019.0  \\\n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity   \n",
       "0             0.16220            0.66560           0.7119  \\\n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  outcome  \n",
       "0                  0.2654          0.4601                  0.11890        0  \n",
       "1                  0.1860          0.2750                  0.08902        0  \n",
       "2                  0.2430          0.3613                  0.08758        0  \n",
       "3                  0.2575          0.6638                  0.17300        0  \n",
       "4                  0.1625          0.2364                  0.07678        0  \n",
       "..                    ...             ...                      ...      ...  \n",
       "564                0.2216          0.2060                  0.07115        0  \n",
       "565                0.1628          0.2572                  0.06637        0  \n",
       "566                0.1418          0.2218                  0.07820        0  \n",
       "567                0.2650          0.4087                  0.12400        0  \n",
       "568                0.0000          0.2871                  0.07039        1  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name:  cancer3\n",
      "[flaml.automl.logger: 07-09 12:13:46] {1693} INFO - task = classification\n",
      "[flaml.automl.logger: 07-09 12:13:46] {1700} INFO - Data split method: stratified\n",
      "[flaml.automl.logger: 07-09 12:13:46] {1703} INFO - Evaluation method: holdout\n",
      "[flaml.automl.logger: 07-09 12:13:46] {1801} INFO - Minimizing error metric: 1-accuracy\n",
      "[flaml.automl.logger: 07-09 12:13:46] {1911} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'lrl1']\n",
      "[flaml.automl.logger: 07-09 12:13:46] {2221} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl.logger: 07-09 12:13:46] {2347} INFO - Estimated sufficient time budget=192s. Estimated necessary time budget=4s.\n",
      "[flaml.automl.logger: 07-09 12:13:46] {2394} INFO -  at 0.1s,\testimator lgbm's best error=0.0847,\tbest estimator lgbm's best error=0.0847\n",
      "[flaml.automl.logger: 07-09 12:13:46] {2221} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl.logger: 07-09 12:13:46] {2394} INFO -  at 0.1s,\testimator lgbm's best error=0.0847,\tbest estimator lgbm's best error=0.0847\n",
      "[flaml.automl.logger: 07-09 12:13:46] {2221} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl.logger: 07-09 12:13:46] {2394} INFO -  at 0.2s,\testimator lgbm's best error=0.0847,\tbest estimator lgbm's best error=0.0847\n",
      "[flaml.automl.logger: 07-09 12:13:46] {2221} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl.logger: 07-09 12:13:46] {2394} INFO -  at 0.2s,\testimator lgbm's best error=0.0678,\tbest estimator lgbm's best error=0.0678\n",
      "[flaml.automl.logger: 07-09 12:13:46] {2221} INFO - iteration 4, current learner xgboost\n",
      "[flaml.automl.logger: 07-09 12:13:46] {2394} INFO -  at 0.3s,\testimator xgboost's best error=0.0847,\tbest estimator lgbm's best error=0.0678\n",
      "[flaml.automl.logger: 07-09 12:13:46] {2221} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl.logger: 07-09 12:13:46] {2394} INFO -  at 0.3s,\testimator lgbm's best error=0.0508,\tbest estimator lgbm's best error=0.0508\n",
      "[flaml.automl.logger: 07-09 12:13:46] {2221} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl.logger: 07-09 12:13:46] {2394} INFO -  at 0.4s,\testimator lgbm's best error=0.0508,\tbest estimator lgbm's best error=0.0508\n",
      "[flaml.automl.logger: 07-09 12:13:46] {2221} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl.logger: 07-09 12:13:46] {2394} INFO -  at 0.4s,\testimator lgbm's best error=0.0508,\tbest estimator lgbm's best error=0.0508\n",
      "[flaml.automl.logger: 07-09 12:13:46] {2221} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl.logger: 07-09 12:13:46] {2394} INFO -  at 0.4s,\testimator lgbm's best error=0.0508,\tbest estimator lgbm's best error=0.0508\n",
      "[flaml.automl.logger: 07-09 12:13:46] {2221} INFO - iteration 9, current learner extra_tree\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2394} INFO -  at 0.4s,\testimator extra_tree's best error=0.1017,\tbest estimator lgbm's best error=0.0508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benepstein/Documents/GitHub/domino-dca-notebooks/.venv/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 07-09 12:13:47] {2221} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2394} INFO -  at 0.4s,\testimator lgbm's best error=0.0508,\tbest estimator lgbm's best error=0.0508\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2221} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2394} INFO -  at 0.5s,\testimator xgboost's best error=0.0847,\tbest estimator lgbm's best error=0.0508\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2221} INFO - iteration 12, current learner extra_tree\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2394} INFO -  at 0.5s,\testimator extra_tree's best error=0.1017,\tbest estimator lgbm's best error=0.0508\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2221} INFO - iteration 13, current learner rf\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2394} INFO -  at 0.5s,\testimator rf's best error=0.1186,\tbest estimator lgbm's best error=0.0508\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2221} INFO - iteration 14, current learner rf\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2394} INFO -  at 0.6s,\testimator rf's best error=0.0508,\tbest estimator lgbm's best error=0.0508\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2221} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2394} INFO -  at 0.6s,\testimator xgboost's best error=0.0508,\tbest estimator lgbm's best error=0.0508\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2221} INFO - iteration 16, current learner lgbm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benepstein/Documents/GitHub/domino-dca-notebooks/.venv/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/benepstein/Documents/GitHub/domino-dca-notebooks/.venv/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 07-09 12:13:47] {2394} INFO -  at 0.6s,\testimator lgbm's best error=0.0339,\tbest estimator lgbm's best error=0.0339\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2221} INFO - iteration 17, current learner extra_tree\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2394} INFO -  at 0.7s,\testimator extra_tree's best error=0.1017,\tbest estimator lgbm's best error=0.0339\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2221} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2394} INFO -  at 0.7s,\testimator lgbm's best error=0.0339,\tbest estimator lgbm's best error=0.0339\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2221} INFO - iteration 19, current learner xgboost\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2394} INFO -  at 0.8s,\testimator xgboost's best error=0.0508,\tbest estimator lgbm's best error=0.0339\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2221} INFO - iteration 20, current learner rf\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2394} INFO -  at 0.8s,\testimator rf's best error=0.0508,\tbest estimator lgbm's best error=0.0339\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2221} INFO - iteration 21, current learner rf\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2394} INFO -  at 0.9s,\testimator rf's best error=0.0339,\tbest estimator lgbm's best error=0.0339\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2221} INFO - iteration 22, current learner lgbm\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2394} INFO -  at 0.9s,\testimator lgbm's best error=0.0339,\tbest estimator lgbm's best error=0.0339\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2221} INFO - iteration 23, current learner lgbm\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2394} INFO -  at 0.9s,\testimator lgbm's best error=0.0339,\tbest estimator lgbm's best error=0.0339\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2221} INFO - iteration 24, current learner xgboost\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2394} INFO -  at 0.9s,\testimator xgboost's best error=0.0508,\tbest estimator lgbm's best error=0.0339\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2221} INFO - iteration 25, current learner extra_tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benepstein/Documents/GitHub/domino-dca-notebooks/.venv/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/benepstein/Documents/GitHub/domino-dca-notebooks/.venv/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 07-09 12:13:47] {2394} INFO -  at 1.0s,\testimator extra_tree's best error=0.1017,\tbest estimator lgbm's best error=0.0339\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2221} INFO - iteration 26, current learner lgbm\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2394} INFO -  at 1.1s,\testimator lgbm's best error=0.0339,\tbest estimator lgbm's best error=0.0339\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2221} INFO - iteration 27, current learner xgboost\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2394} INFO -  at 1.1s,\testimator xgboost's best error=0.0508,\tbest estimator lgbm's best error=0.0339\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2221} INFO - iteration 28, current learner extra_tree\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2394} INFO -  at 1.1s,\testimator extra_tree's best error=0.1017,\tbest estimator lgbm's best error=0.0339\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2221} INFO - iteration 29, current learner extra_tree\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2394} INFO -  at 1.2s,\testimator extra_tree's best error=0.1017,\tbest estimator lgbm's best error=0.0339\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2221} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2394} INFO -  at 1.2s,\testimator lgbm's best error=0.0339,\tbest estimator lgbm's best error=0.0339\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2221} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2394} INFO -  at 1.2s,\testimator lgbm's best error=0.0339,\tbest estimator lgbm's best error=0.0339\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2221} INFO - iteration 32, current learner lgbm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benepstein/Documents/GitHub/domino-dca-notebooks/.venv/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 07-09 12:13:47] {2394} INFO -  at 1.3s,\testimator lgbm's best error=0.0339,\tbest estimator lgbm's best error=0.0339\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2221} INFO - iteration 33, current learner extra_tree\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2394} INFO -  at 1.3s,\testimator extra_tree's best error=0.1017,\tbest estimator lgbm's best error=0.0339\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2221} INFO - iteration 34, current learner lgbm\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2394} INFO -  at 1.3s,\testimator lgbm's best error=0.0339,\tbest estimator lgbm's best error=0.0339\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2221} INFO - iteration 35, current learner rf\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2394} INFO -  at 1.4s,\testimator rf's best error=0.0339,\tbest estimator lgbm's best error=0.0339\n",
      "[flaml.automl.logger: 07-09 12:13:47] {2221} INFO - iteration 36, current learner extra_tree\n",
      "[flaml.automl.logger: 07-09 12:13:48] {2394} INFO -  at 1.4s,\testimator extra_tree's best error=0.0339,\tbest estimator lgbm's best error=0.0339\n",
      "[flaml.automl.logger: 07-09 12:13:48] {2221} INFO - iteration 37, current learner rf\n",
      "[flaml.automl.logger: 07-09 12:13:48] {2394} INFO -  at 1.5s,\testimator rf's best error=0.0339,\tbest estimator lgbm's best error=0.0339\n",
      "[flaml.automl.logger: 07-09 12:13:48] {2221} INFO - iteration 38, current learner xgboost\n",
      "[flaml.automl.logger: 07-09 12:13:48] {2394} INFO -  at 1.5s,\testimator xgboost's best error=0.0508,\tbest estimator lgbm's best error=0.0339\n",
      "[flaml.automl.logger: 07-09 12:13:48] {2221} INFO - iteration 39, current learner rf\n",
      "[flaml.automl.logger: 07-09 12:13:48] {2394} INFO -  at 1.5s,\testimator rf's best error=0.0339,\tbest estimator lgbm's best error=0.0339\n",
      "[flaml.automl.logger: 07-09 12:13:48] {2221} INFO - iteration 40, current learner xgboost\n",
      "[flaml.automl.logger: 07-09 12:13:48] {2394} INFO -  at 1.6s,\testimator xgboost's best error=0.0508,\tbest estimator lgbm's best error=0.0339\n",
      "[flaml.automl.logger: 07-09 12:13:48] {2221} INFO - iteration 41, current learner extra_tree\n",
      "[flaml.automl.logger: 07-09 12:13:48] {2394} INFO -  at 1.6s,\testimator extra_tree's best error=0.0339,\tbest estimator lgbm's best error=0.0339\n",
      "[flaml.automl.logger: 07-09 12:13:48] {2221} INFO - iteration 42, current learner lgbm\n",
      "[flaml.automl.logger: 07-09 12:13:48] {2394} INFO -  at 1.6s,\testimator lgbm's best error=0.0339,\tbest estimator lgbm's best error=0.0339\n",
      "[flaml.automl.logger: 07-09 12:13:48] {2221} INFO - iteration 43, current learner xgboost\n",
      "[flaml.automl.logger: 07-09 12:13:48] {2394} INFO -  at 1.6s,\testimator xgboost's best error=0.0508,\tbest estimator lgbm's best error=0.0339\n",
      "[flaml.automl.logger: 07-09 12:13:48] {2221} INFO - iteration 44, current learner extra_tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benepstein/Documents/GitHub/domino-dca-notebooks/.venv/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/benepstein/Documents/GitHub/domino-dca-notebooks/.venv/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/benepstein/Documents/GitHub/domino-dca-notebooks/.venv/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 07-09 12:13:48] {2394} INFO -  at 1.7s,\testimator extra_tree's best error=0.0339,\tbest estimator lgbm's best error=0.0339\n",
      "[flaml.automl.logger: 07-09 12:13:48] {2221} INFO - iteration 45, current learner xgboost\n",
      "[flaml.automl.logger: 07-09 12:13:48] {2394} INFO -  at 1.7s,\testimator xgboost's best error=0.0508,\tbest estimator lgbm's best error=0.0339\n",
      "[flaml.automl.logger: 07-09 12:13:48] {2221} INFO - iteration 46, current learner rf\n",
      "[flaml.automl.logger: 07-09 12:13:48] {2394} INFO -  at 1.8s,\testimator rf's best error=0.0339,\tbest estimator lgbm's best error=0.0339\n",
      "[flaml.automl.logger: 07-09 12:13:48] {2221} INFO - iteration 47, current learner extra_tree\n",
      "[flaml.automl.logger: 07-09 12:13:48] {2394} INFO -  at 1.8s,\testimator extra_tree's best error=0.0339,\tbest estimator lgbm's best error=0.0339\n",
      "[flaml.automl.logger: 07-09 12:13:48] {2221} INFO - iteration 48, current learner lgbm\n",
      "[flaml.automl.logger: 07-09 12:13:48] {2394} INFO -  at 1.9s,\testimator lgbm's best error=0.0339,\tbest estimator lgbm's best error=0.0339\n",
      "[flaml.automl.logger: 07-09 12:13:48] {2221} INFO - iteration 49, current learner rf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benepstein/Documents/GitHub/domino-dca-notebooks/.venv/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 07-09 12:13:48] {2394} INFO -  at 1.9s,\testimator rf's best error=0.0339,\tbest estimator lgbm's best error=0.0339\n",
      "[flaml.automl.logger: 07-09 12:13:48] {2630} INFO - retrain lgbm for 0.0s\n",
      "[flaml.automl.logger: 07-09 12:13:48] {2633} INFO - retrained model: LGBMClassifier(colsample_bytree=0.7342686157264448,\n",
      "               learning_rate=0.11767862896996559, max_bin=511,\n",
      "               min_child_samples=8, n_estimators=16, num_leaves=12,\n",
      "               reg_alpha=0.000999728671408746, reg_lambda=0.024175625231164698,\n",
      "               verbose=-1)\n",
      "[flaml.automl.logger: 07-09 12:13:48] {1941} INFO - fit succeeded\n",
      "[flaml.automl.logger: 07-09 12:13:48] {1942} INFO - Time taken to find the best model: 0.6334359645843506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benepstein/Documents/GitHub/domino-dca-notebooks/.venv/lib/python3.9/site-packages/mlflow/models/signature.py:145: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  outputs = _infer_schema(model_output) if model_output is not None else None\n",
      "/Users/benepstein/Documents/GitHub/domino-dca-notebooks/.venv/lib/python3.9/site-packages/mlflow/models/signature.py:145: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  outputs = _infer_schema(model_output) if model_output is not None else None\n"
     ]
    }
   ],
   "source": [
    "from flaml import AutoML\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "import pandas as pd\n",
    "from typing import Optional, Tuple\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Experiment setup\n",
    "experiment_name = \"flaml-testing\"\n",
    "label = \"outcome\"\n",
    "df_automl = df.copy()\n",
    "display(df_automl)\n",
    "experiment = mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# No runs can be active before we start. We will create a run\n",
    "while mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "mlflow.autolog(disable=True)\n",
    "\n",
    "\n",
    "def set_best_run() -> Optional[str]:\n",
    "    \"\"\"Finds the best run and sets the parent run results based on the best run\"\"\"\n",
    "    best_run = mlflow.search_runs(\n",
    "        experiment_ids=[experiment.experiment_id],\n",
    "        filter_string=f'params.best_config = \"{automl.best_config}\"',\n",
    "    )\n",
    "    if not len(best_run):\n",
    "        return\n",
    "    best_run_id = best_run.run_id[0]\n",
    "    mlflow.set_tag(\"Best run\", best_run_id)\n",
    "\n",
    "    # Copy the params and metrics from the winning run to the parent\n",
    "    run_params = best_run[[c for c in best_run.columns if c.startswith(\"params.\")]].to_dict()\n",
    "    run_params = {k.lstrip(\"params.\"): v[0] for k, v in run_params.items()}\n",
    "    mlflow.log_params(run_params)\n",
    "\n",
    "    run_metrics = best_run[[c for c in best_run.columns if c.startswith(\"metrics.\")]].to_dict()\n",
    "    run_metrics = {k.lstrip(\"metrics.\"): v[0] for k, v in run_metrics.items()}\n",
    "    mlflow.log_metrics(run_metrics)\n",
    "    return best_run_id\n",
    "\n",
    "\n",
    "def log_best_model(automl: AutoML, df_automl: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    train = df_automl.drop(label, axis=1)[:5]\n",
    "    predictions = pd.DataFrame({label: automl.predict(train)})\n",
    "    mlflow.sklearn.log_model(\n",
    "        automl, \n",
    "        \"model\", \n",
    "        signature=infer_signature(train, predictions), \n",
    "        input_example=train\n",
    "    )\n",
    "    return train, predictions\n",
    "\n",
    "\n",
    "def log_winning_metrics(automl: AutoML) -> None:\n",
    "    \"\"\"Log the accuracy, precision, recall, and f1 of the best model\"\"\"\n",
    "    labels = df_automl[label]\n",
    "    all_preds = automl.predict(df_automl.drop(label, axis=1))\n",
    "    mlflow.log_metric(\"accuracy\", float(accuracy_score(labels, all_preds)))\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(labels, all_preds)\n",
    "    mlflow.log_metric(\"precision\", float(prec.mean()))\n",
    "    mlflow.log_metric(\"recall\", float(rec.mean()))\n",
    "    mlflow.log_metric(\"f1\", float(f1.mean()))\n",
    "\n",
    "\n",
    "with mlflow.start_run(run_name=\"cancer\") as run:\n",
    "    run_name = run.data.tags[\"mlflow.runName\"]\n",
    "    print(\"Run name: \", run_name)\n",
    "    display(dca.automl.OpenExperiment(experiment_name))\n",
    "    automl = AutoML(metric=\"accuracy\")\n",
    "    automl.fit(\n",
    "        dataframe=df_automl, \n",
    "        label=label, \n",
    "        task=\"classification\", \n",
    "        time_budget=300, \n",
    "        max_iter=50, \n",
    "        eval_method=\"holdout\", \n",
    "        split_ratio=0.1\n",
    "    )\n",
    "    \n",
    "    # Save the winning run content\n",
    "    train, predictions = log_best_model(automl, df_automl)\n",
    "    log_winning_metrics(automl)\n",
    "    best_run_id = set_best_run()\n",
    "\n",
    "    # Log the notebook cell execution history for reproducibility\n",
    "    dca.mlflow_log_notebook(run_name)\n",
    "\n",
    "    \n",
    "# Set the wining run to be tagged as the winner\n",
    "# And log the model\n",
    "if best_run_id:\n",
    "    with mlflow.start_run(best_run_id):\n",
    "        mlflow.set_tag(\"Status\", \"Winner\")\n",
    "        mlflow.set_tag(\"Winner\", True)\n",
    "        mlflow.sklearn.log_model(\n",
    "            automl, \n",
    "            \"model\", \n",
    "            signature=infer_signature(train, predictions), \n",
    "            input_example=train\n",
    "        )\n",
    "        log_winning_metrics(automl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7523483",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
