{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlflow in /home/ubuntu/.local/lib/python3.8/site-packages (2.3.1)\n",
      "Requirement already satisfied: transformers in /home/ubuntu/.local/lib/python3.8/site-packages (4.28.1)\n",
      "Requirement already satisfied: datasets in /home/ubuntu/.local/lib/python3.8/site-packages (2.12.0)\n",
      "Requirement already satisfied: evaluate in /home/ubuntu/.local/lib/python3.8/site-packages (0.4.0)\n",
      "Requirement already satisfied: seqeval in /home/ubuntu/.local/lib/python3.8/site-packages (1.2.2)\n",
      "Requirement already satisfied: torch in /home/ubuntu/.local/lib/python3.8/site-packages (2.0.0)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.15.1-cp38-cp38-manylinux1_x86_64.whl (33.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 33.8 MB 5.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz<2024 in /home/ubuntu/.local/lib/python3.8/site-packages (from mlflow) (2023.3)\n",
      "Requirement already satisfied: gunicorn<21; platform_system != \"Windows\" in /home/ubuntu/.local/lib/python3.8/site-packages (from mlflow) (20.1.0)\n",
      "Requirement already satisfied: scikit-learn<2 in /home/ubuntu/.local/lib/python3.8/site-packages (from mlflow) (1.2.2)\n",
      "Requirement already satisfied: matplotlib<4 in /usr/lib/python3/dist-packages (from mlflow) (3.1.2)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /home/ubuntu/.local/lib/python3.8/site-packages (from mlflow) (1.10.4)\n",
      "Requirement already satisfied: scipy<2 in /home/ubuntu/.local/lib/python3.8/site-packages (from mlflow) (1.10.1)\n",
      "Requirement already satisfied: packaging<24 in /home/ubuntu/.local/lib/python3.8/site-packages (from mlflow) (23.1)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/lib/python3/dist-packages (from mlflow) (5.3.1)\n",
      "Requirement already satisfied: docker<7,>=4.0.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from mlflow) (6.1.0)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11; platform_system != \"Windows\" in /home/ubuntu/.local/lib/python3.8/site-packages (from mlflow) (3.1.2)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<7,>=3.7.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from mlflow) (6.6.0)\n",
      "Requirement already satisfied: cloudpickle<3 in /home/ubuntu/.local/lib/python3.8/site-packages (from mlflow) (2.2.1)\n",
      "Requirement already satisfied: entrypoints<1 in /home/ubuntu/.local/lib/python3.8/site-packages (from mlflow) (0.4)\n",
      "Requirement already satisfied: Flask<3 in /home/ubuntu/.local/lib/python3.8/site-packages (from mlflow) (2.3.2)\n",
      "Requirement already satisfied: pandas<3 in /home/ubuntu/.local/lib/python3.8/site-packages (from mlflow) (2.0.1)\n",
      "Requirement already satisfied: gitpython<4,>=2.1.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from mlflow) (3.1.31)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from mlflow) (2.0.12)\n",
      "Requirement already satisfied: pyarrow<12,>=4.0.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from mlflow) (11.0.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from mlflow) (8.1.3)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /home/ubuntu/.local/lib/python3.8/site-packages (from mlflow) (3.4.3)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from mlflow) (0.4.4)\n",
      "Requirement already satisfied: databricks-cli<1,>=0.8.7 in /home/ubuntu/.local/lib/python3.8/site-packages (from mlflow) (0.17.6)\n",
      "Requirement already satisfied: protobuf<5,>=3.12.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from mlflow) (4.22.4)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /usr/lib/python3/dist-packages (from mlflow) (2.22.0)\n",
      "Requirement already satisfied: querystring-parser<2 in /home/ubuntu/.local/lib/python3.8/site-packages (from mlflow) (1.2.4)\n",
      "Requirement already satisfied: numpy<2 in /home/ubuntu/.local/lib/python3.8/site-packages (from mlflow) (1.24.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/.local/lib/python3.8/site-packages (from transformers) (3.12.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ubuntu/.local/lib/python3.8/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/.local/lib/python3.8/site-packages (from transformers) (2023.5.5)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from datasets) (2023.4.0)\n",
      "Requirement already satisfied: responses<0.19 in /home/ubuntu/.local/lib/python3.8/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: xxhash in /home/ubuntu/.local/lib/python3.8/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /home/ubuntu/.local/lib/python3.8/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: aiohttp in /home/ubuntu/.local/lib/python3.8/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ubuntu/.local/lib/python3.8/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ubuntu/.local/lib/python3.8/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: typing-extensions in /home/ubuntu/.local/lib/python3.8/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in /home/ubuntu/.local/lib/python3.8/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ubuntu/.local/lib/python3.8/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ubuntu/.local/lib/python3.8/site-packages (from torch) (10.2.10.91)\n",
      "Requirement already satisfied: triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ubuntu/.local/lib/python3.8/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: networkx in /home/ubuntu/.local/lib/python3.8/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ubuntu/.local/lib/python3.8/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ubuntu/.local/lib/python3.8/site-packages (from torch) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ubuntu/.local/lib/python3.8/site-packages (from torch) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ubuntu/.local/lib/python3.8/site-packages (from torch) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ubuntu/.local/lib/python3.8/site-packages (from torch) (11.7.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ubuntu/.local/lib/python3.8/site-packages (from torch) (2.14.3)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ubuntu/.local/lib/python3.8/site-packages (from torch) (8.5.0.96)\n",
      "Collecting pillow!=8.3.*,>=5.3.0\n",
      "  Downloading Pillow-9.5.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 54.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=3.0 in /usr/lib/python3/dist-packages (from gunicorn<21; platform_system != \"Windows\"->mlflow) (45.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from scikit-learn<2->mlflow) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from scikit-learn<2->mlflow) (3.1.0)\n",
      "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /home/ubuntu/.local/lib/python3.8/site-packages (from alembic!=1.10.0,<2->mlflow) (5.12.0)\n",
      "Requirement already satisfied: Mako in /home/ubuntu/.local/lib/python3.8/site-packages (from alembic!=1.10.0,<2->mlflow) (1.2.4)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from docker<7,>=4.0.0->mlflow) (1.5.1)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from docker<7,>=4.0.0->mlflow) (2.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from Jinja2<4,>=2.11; platform_system != \"Windows\"->mlflow) (2.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ubuntu/.local/lib/python3.8/site-packages (from importlib-metadata!=4.7.0,<7,>=3.7.0->mlflow) (3.15.0)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /home/ubuntu/.local/lib/python3.8/site-packages (from Flask<3->mlflow) (1.6.2)\n",
      "Requirement already satisfied: Werkzeug>=2.3.3 in /home/ubuntu/.local/lib/python3.8/site-packages (from Flask<3->mlflow) (2.3.3)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /home/ubuntu/.local/lib/python3.8/site-packages (from Flask<3->mlflow) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ubuntu/.local/lib/python3.8/site-packages (from pandas<3->mlflow) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from pandas<3->mlflow) (2023.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from gitpython<4,>=2.1.0->mlflow) (4.0.10)\n",
      "Requirement already satisfied: greenlet!=0.4.17; platform_machine == \"aarch64\" or (platform_machine == \"ppc64le\" or (platform_machine == \"x86_64\" or (platform_machine == \"amd64\" or (platform_machine == \"AMD64\" or (platform_machine == \"win32\" or platform_machine == \"WIN32\"))))) in /home/ubuntu/.local/lib/python3.8/site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (2.0.2)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /home/ubuntu/.local/lib/python3.8/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (0.9.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/lib/python3/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.14.0)\n",
      "Requirement already satisfied: oauthlib>=3.1.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (3.2.2)\n",
      "Requirement already satisfied: pyjwt>=1.7.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (2.6.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ubuntu/.local/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from aiohttp->datasets) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ubuntu/.local/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ubuntu/.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch) (0.34.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ubuntu/.local/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: lit in /home/ubuntu/.local/lib/python3.8/site-packages (from triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch) (16.0.2)\n",
      "Requirement already satisfied: cmake in /home/ubuntu/.local/lib/python3.8/site-packages (from triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch) (3.26.3)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow) (5.0.0)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/lib/python3/dist-packages (from yarl<2.0,>=1.0->aiohttp->datasets) (2.8)\n",
      "Installing collected packages: pillow, torchvision\n",
      "Successfully installed pillow-9.5.0 torchvision-0.15.1\n"
     ]
    }
   ],
   "source": [
    "!pip install mlflow transformers datasets evaluate seqeval torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.2) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "/home/ubuntu/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, load_metric\n",
    "from huggingface_hub import notebook_login\n",
    "from matplotlib import pyplot as plt\n",
    "from transformers import (\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "import mlflow\n",
    "\n",
    "# Only available in Jupyter\n",
    "# notebook_login() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wnut_17 (/home/ubuntu/.cache/huggingface/datasets/wnut_17/wnut_17/1.0.0/077c7f08b8dbc800692e8c9186cdf3606d5849ab0e7be662e6135bb10eba54f9)\n",
      "100%|██████████| 3/3 [00:00<00:00, 545.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splits: ['train', 'validation', 'test']\n",
      "Columns ['id', 'tokens', 'ner_tags']\n",
      "Labels ['O', 'B-corporation', 'I-corporation', 'B-creative-work', 'I-creative-work', 'B-group', 'I-group', 'B-location', 'I-location', 'B-person', 'I-person', 'B-product', 'I-product']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load our DatasetDict\n",
    "ds = load_dataset(\"wnut_17\")\n",
    "print(\"Splits:\", list(ds.keys()))\n",
    "print(\"Columns\", list(ds[\"train\"][0].keys()))\n",
    "# Extract our labels\n",
    "tags_name = \"tags\" if \"tags\" in ds[\"train\"].features else \"ner_tags\"\n",
    "assert tags_name in ds[\"train\"].features, (\n",
    "    \"Your dataset must have `tags` or `ner_tags` to perform token classification\"\n",
    ")\n",
    "\n",
    "labels = ds[\"train\"].features[tags_name].feature.names\n",
    "print(\"Labels\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model we will be fine-tuning\n",
    "HF_MODEL = \"distilbert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(HF_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/wnut_17/wnut_17/1.0.0/077c7f08b8dbc800692e8c9186cdf3606d5849ab0e7be662e6135bb10eba54f9/cache-129ca94b3046f87f.arrow\n",
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/wnut_17/wnut_17/1.0.0/077c7f08b8dbc800692e8c9186cdf3606d5849ab0e7be662e6135bb10eba54f9/cache-358d7c3148e7c56f.arrow\n",
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/wnut_17/wnut_17/1.0.0/077c7f08b8dbc800692e8c9186cdf3606d5849ab0e7be662e6135bb10eba54f9/cache-e3d161d63d639061.arrow\n"
     ]
    }
   ],
   "source": [
    "from datasets.formatting.formatting import LazyBatch\n",
    "from transformers import BatchEncoding\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    \"\"\"Tokenize inputs and align token values to their labels\n",
    "    \n",
    "    Specifically, when tokenizing, special tokens such as [CLS] and [SEP] which create mismatches between\n",
    "    actual token inputs and their labels. \n",
    "    \n",
    "    We realign the tokens and labels bt:\n",
    "        1. Mapping all tokens to their corresponding word with the word_ids method.\n",
    "        2. Assigning the label -100 to the special tokens [CLS] and [SEP] \n",
    "            so they’re ignored by the PyTorch loss function.\n",
    "        3. Only labeling the first token of a given word. Assign -100 to \n",
    "            other subtokens from the same word.\n",
    "            \n",
    "    For more information, see: https://huggingface.co/docs/transformers/tasks/token_classification\n",
    "    \"\"\"\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[tags_name]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "\n",
    "ds_encoded = ds.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "# (Assuming PyTorch) we create a collator to pad the sentences to the max \n",
    "# input length during batch creation\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from transformers import EvalPrediction\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "# In token classification, we use seqeval to compute metrics. \n",
    "# We don't take this from the user\n",
    "seqeval = evaluate.load(\"seqeval\")\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    \"\"\"We use seqeval during training to compute precision, recall, f1, and accuracy\n",
    "    \n",
    "    Seqeval is the standard for metric computation in token classification. \n",
    "    We preprocess the predictions and labels to remove the -100 ([CLS] and [SEP] tokens)\n",
    "    \"\"\"\n",
    "    predictions, prediction_labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [labels[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, prediction_labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [labels[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, prediction_labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForTokenClassification: ['vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# In order to create our model, we create idx2label and label2idx maps\n",
    "\n",
    "id2label = {idx: label for idx, label in enumerate(labels)}\n",
    "label2id = {label: idx for idx, label in enumerate(labels)}\n",
    "\n",
    "# Now load our model to fine-tune\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    HF_MODEL, num_labels=len(labels), id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# https://huggingface.co/docs/transformers/v4.20.1/en/main_classes/callback#transformers.integrations.MLflowCallback\n",
    "# os.environ[\"MLFLOW_EXPERIMENT_NAME\"] = \"trainer-mlflow-demo\"\n",
    "\n",
    "# Name taken from user\n",
    "exp = mlflow.set_experiment(\"mlflow-huggingface-demo\")\n",
    "os.environ[\"MLFLOW_FLATTEN_PARAMS\"] = \"1\"\n",
    "os.environ[\"HF_MLFLOW_LOG_ARTIFACTS\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_strategy = \"epoch\"  # Batch or epoch, take from user\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "#     hub_model_id=\"juliensimon/bert-finetune-wnut\",  # If we want to push_to_hub, this must be set\n",
    "    learning_rate=2e-5,  # Take from user, this is the default\n",
    "    per_device_train_batch_size=16, # Take from user, this is the default\n",
    "    per_device_eval_batch_size=16,  # Take from user, this is the default\n",
    "    weight_decay=0.01,  # Take from user, this is the default\n",
    "    num_train_epochs=5,  # From the user\n",
    "    output_dir=\"./output\",  # From the user, default value\n",
    "    logging_steps=500,      # Take from user\n",
    "    evaluation_strategy=eval_strategy,\n",
    "    save_strategy=eval_strategy, \n",
    "    push_to_hub=False,  # From the user, needs to set `hub_model_id` if True\n",
    "    report_to=\"mlflow\",\n",
    "    seed=101,           # Set a seed for reproducibility \n",
    "    load_best_model_at_end=True  # Required if early stopping is True (see next cell)\n",
    "    \n",
    ")\n",
    "\n",
    "has_val = \"validation\" in ds\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    train_dataset=ds_encoded[\"train\"],\n",
    "    eval_dataset=ds_encoded[\"validation\"] if has_val else ds_encoded[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    "    # Ask user if early stopping (default True), and ask for patience (default 1 or 2.. We can decide)\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=1)],  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='639' max='1065' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 639/1065 01:55 < 01:16, 5.53 it/s, Epoch 3/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.244613</td>\n",
       "      <td>0.708511</td>\n",
       "      <td>0.398325</td>\n",
       "      <td>0.509954</td>\n",
       "      <td>0.944370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.223961</td>\n",
       "      <td>0.675302</td>\n",
       "      <td>0.467703</td>\n",
       "      <td>0.552650</td>\n",
       "      <td>0.951618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.175900</td>\n",
       "      <td>0.243177</td>\n",
       "      <td>0.691152</td>\n",
       "      <td>0.495215</td>\n",
       "      <td>0.577003</td>\n",
       "      <td>0.953525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    trainer.train()\n",
    "    components = {\n",
    "        \"model\": model,\n",
    "        \"tokenizer\": tokenizer,\n",
    "    }\n",
    "    mlflow.transformers.log_model(\n",
    "        transformers_model=components,\n",
    "        artifact_path=\"my_model\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
